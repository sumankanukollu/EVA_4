{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "suman_MNIS_with_withOutPyTorchModules.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMM9SNYge//E0xnK0cO80aG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumankanukollu/EVA_4/blob/master/suman_MNIS_with_withOutPyTorchModules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60CFxZb4v-BI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f4cdd815-fa4b-4d48-9468-2f77d99a34aa"
      },
      "source": [
        "import torch\n",
        "a = torch.range(1, 16)\n",
        "#a.reshape(4,4)\n",
        "b=a.view(2,8)\n",
        "print(b)\n",
        "b[0,2]=66\n",
        "print(b)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.],\n",
            "        [ 9., 10., 11., 12., 13., 14., 15., 16.]])\n",
            "tensor([[ 1.,  2., 66.,  4.,  5.,  6.,  7.,  8.],\n",
            "        [ 9., 10., 11., 12., 13., 14., 15., 16.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0pUitfDhigj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notes URL : https://github.com/fastai/fastai_old/blob/master/dev_nb/001a_nn_basics.ipynb\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "DATA_PATH = Path('data')\n",
        "PATH = DATA_PATH/'mnist'\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#https://github.com/mnielsen/neural-networks-and-deep-learning/raw/master/data/mnist.pkl.gz\n",
        "URL='https://github.com/mnielsen/neural-networks-and-deep-learning/raw/master/data/'\n",
        "FILENAME='mnist.pkl.gz'\n",
        "\n",
        "if not (PATH/FILENAME).exists():\n",
        "    content = requests.get(URL+FILENAME).content\n",
        "    (PATH/FILENAME).open('wb').write(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQrVy7r4o1q-",
        "colab_type": "code",
        "outputId": "7dc91fc6-dd19-414c-c2cf-02922b4c054a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import os\n",
        "for r,d,f in os.walk(os.path.join(os.getcwd(),'data')):\n",
        "  print(r)\n",
        "  print(d)\n",
        "  print(f)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n",
            "['mnist']\n",
            "[]\n",
            "/content/data/mnist\n",
            "[]\n",
            "['mnist.pkl.gz']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gc7pxbvpEp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle, gzip\n",
        "\n",
        "with gzip.open(PATH/FILENAME, 'rb') as f:\n",
        "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVHoyk6y365G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a207c855-7db9-47cc-f2a8-44db351d45eb"
      },
      "source": [
        "print(x_train.ndim)\n",
        "print(x_train.shape)\n",
        "print(x_train.size)\n",
        "\n",
        "print(y_train.ndim)\n",
        "print(y_train.shape)\n",
        "print(y_train.size)\n",
        "\n",
        "\n",
        "\n",
        "print(x_valid.ndim)\n",
        "print(x_valid.shape)\n",
        "print(x_valid.size)\n",
        "\n",
        "\n",
        "\n",
        "print(y_valid.ndim)\n",
        "print(y_valid.shape)\n",
        "print(y_valid.size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "(50000, 784)\n",
            "39200000\n",
            "1\n",
            "(50000,)\n",
            "50000\n",
            "2\n",
            "(10000, 784)\n",
            "7840000\n",
            "1\n",
            "(10000,)\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K674YqDipnyk",
        "colab_type": "code",
        "outputId": "940bf6f8-58e7-4bc8-c6a2-43c474b509c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape((28,28)), cmap=\"gray\")\n",
        "x_train.shape\n",
        "print(len(x_train[0]))\n",
        "\n",
        "print('y_train is : %s'%y_train[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n",
            "y_train is : 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDYNJJ9Z5l5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "84c85bcd-1eae-4e79-f0bc-3cef50484ab1"
      },
      "source": [
        "pyplot.imshow(x_valid[0].reshape((28,28)), cmap=\"gray\")\n",
        "x_valid.shape\n",
        "\n",
        "print('y_valid value is : %s'%y_valid[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_valid value is : 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL7rpScYZFoRrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m83GrRxprNOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fb3a313a-0dbb-4a0d-b927-aed392e56fdc"
      },
      "source": [
        "import torch \n",
        "\n",
        "x_train,y_train,x_valid,y_valid = map(torch.tensor, (x_train,y_train,x_valid,y_valid))\n",
        "n,c = x_train.shape\n",
        "x_train, x_train.shape, y_train.min(), y_train.max(),y_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " torch.Size([50000, 784]),\n",
              " tensor(0),\n",
              " tensor(9),\n",
              " torch.Size([50000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7nA3XXyrYhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "weights = torch.randn(784,10)/math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCnMIpT4uw7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "78549ba2-b67d-42c7-bbb2-b2ca0d7d4f0d"
      },
      "source": [
        "print(weights)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0023, -0.0486,  0.0627,  ..., -0.0029,  0.0163,  0.0305],\n",
            "        [ 0.0384,  0.0429,  0.0487,  ..., -0.0289, -0.0060, -0.0125],\n",
            "        [-0.0265,  0.0370,  0.0239,  ..., -0.0159, -0.0617, -0.0332],\n",
            "        ...,\n",
            "        [ 0.0284, -0.0156, -0.0114,  ...,  0.0119,  0.0170, -0.0020],\n",
            "        [ 0.0699,  0.0051,  0.0114,  ..., -0.0521,  0.0262,  0.0325],\n",
            "        [-0.0278, -0.0072, -0.0489,  ...,  0.0188,  0.0126,  0.0473]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHb8oSkIvEwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):      return log_softmax(xb @ weights + bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU0a1e0xlhiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2d33c9b3-74dc-4f16-d77f-01a54202ef81"
      },
      "source": [
        "#### Log_softmax explanation\n",
        "def log_softmax2(x): return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "import numpy as np\n",
        "tmp = np.array([[5,4,2],[4,2,8],[4,4,1]],dtype='float')\n",
        "tmp_tens = torch.tensor(tmp)\n",
        "print(tmp_tens)\n",
        "log_softmax(tmp_tens)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5., 4., 2.],\n",
            "        [4., 2., 8.],\n",
            "        [4., 4., 1.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3490, -1.3490, -3.3490],\n",
              "        [-4.0206, -6.0206, -0.0206],\n",
              "        [-0.7177, -0.7177, -3.7177]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f12D32Clvxmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0405f2ed-350f-451d-e775-a379c19def7a"
      },
      "source": [
        "print(x_train[0].ndim)\n",
        "print(x_train[0].shape)\n",
        "print(x_train[0].size)\n",
        "model(x_train[0:64]).shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "torch.Size([784])\n",
            "<built-in method size of Tensor object at 0x7f382f10ac60>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siEGou08vcWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9d7f18aa-3599-4313-a74d-ef4406e28b90"
      },
      "source": [
        "bs=64                  # batch size\n",
        "\n",
        "xb = x_train[0:bs]     # a mini-batch from x\n",
        "preds = model(xb)      # predictions\n",
        "print(preds.shape)\n",
        "print(len(preds[0]))\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.2456, -2.5395, -2.2962, -1.9823, -2.5221, -2.0454, -2.6195, -2.4066,\n",
              "         -2.1996, -2.3707], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b4y7gGowVrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d592083f-b0c1-4e9e-9f5f-0edcde447320"
      },
      "source": [
        "print(weights.shape)\n",
        "print(bias.shape)\n",
        "print(x_train[0:64].shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([784, 10])\n",
            "torch.Size([10])\n",
            "torch.Size([64, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "239rJPltwZhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]), target].mean()\n",
        "loss_func = nll"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLbvgbnM-2Tw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "89c47544-e428-4f3c-fbfb-07991077ab8e"
      },
      "source": [
        "y_train[0:64]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
              "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
              "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc0z1c2yyQXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "697b647d-c5f4-4924-8704-5d4ec91e03db"
      },
      "source": [
        "yb=y_train[0:bs]\n",
        "yb\n",
        "loss_func(preds,yb)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3390, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt5Qqy3cybDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds==yb).float().mean()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtFmqq_czMQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49d6a690-c1d1-45c5-f38e-3da17e78ad5e"
      },
      "source": [
        "accuracy(preds,yb)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CqYbOGDzQOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "lr = 0.5   # learning rate\n",
        "epochs = 2 # how many epochs to train for"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ienCa1QzrQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "051c4a4b-f3c0-48fe-e219-ae8188d33905"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    print(epoch)\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        #set_trace()\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McdA9WzezzDu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ade404c-d42c-428f-e0f2-7add0be4d78c"
      },
      "source": [
        "\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0810, grad_fn=<NegBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk-Bgy_I0qL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25b71d4b-e966-4986-f5fd-16b5f945c005"
      },
      "source": [
        "###########################################################\n",
        "# *Using torch.nn.functional*\n",
        "'''\n",
        "1. replace activation and loss functions with nn.functional module\n",
        "'''\n",
        "###############################################################"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. replace activation and loss functions with nn.functional module\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJa-WUzqRdnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb): return xb @ weights + bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTUint3WSQTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6873f48d-95d6-476b-a203-06b080b82458"
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0810, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aaf0cf63-fc1c-4824-a557-80694b905d68",
        "id": "N1ZeKrsiaORZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "###########################################################\n",
        "# Refactor using nn.Module\n",
        "'''\n",
        "1. Next up, we'll use nn.Module and nn.Parameter, for a clearer and more concise training loop.\n",
        "We subclass nn.Module (which itself is a class and able to keep track of state). In this case, we want to create a class that holds our weights, bias, and method for the forward step. nn.Module has a number of attributes and methods (such as .parameters() and .zero_grad()) which we will be using.\n",
        "\n",
        "NB: nn.Module (uppercase M) is a PyTorch specific concept, and is a class we'll be using a lot. nn.Module is not to be confused with the Python concept of a (lowercase m) module, which is a file of Python code that can be imported.\n",
        "'''\n",
        "###############################################################"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n1. Next up, we'll use nn.Module and nn.Parameter, for a clearer and more concise training loop.\\nWe subclass nn.Module (which itself is a class and able to keep track of state). In this case, we want to create a class that holds our weights, bias, and method for the forward step. nn.Module has a number of attributes and methods (such as .parameters() and .zero_grad()) which we will be using.\\n\\nNB: nn.Module (uppercase M) is a PyTorch specific concept, and is a class we'll be using a lot. nn.Module is not to be confused with the Python concept of a (lowercase m) module, which is a file of Python code that can be imported.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S9Jr8ovb0AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(784,10)/math.sqrt(784))\n",
        "        self.bias = nn.Parameter(torch.zeros(10))\n",
        "\n",
        "    def forward(self, xb): return xb @ self.weights + self.bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qPv-kEmb2DZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aca9ad1d-e8ea-4bac-da92-3a9a87773bc3"
      },
      "source": [
        "model = Mnist_Logistic()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.4142, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRlAVKpcb5-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs + 1):\n",
        "            start_i = i*bs\n",
        "            end_i = start_i+bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters(): p -= p.grad * lr\n",
        "                model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGsuT066cgch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sXnJ2fAci8p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "060c0f3d-fad4-4f80-c92c-01b7cef14949"
      },
      "source": [
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0799, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8089044f-2c91-432d-8d88-9bcb199b059f",
        "id": "CUMtr0yZcrkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "###########################################################\n",
        "# Refactor using nn.Linear\n",
        "'''\n",
        "1. We continue to refactor our code. \n",
        "      Instead of manually defining and initializing self.weights and self.bias, and calculating xb  @ self.weights + self.bias, \n",
        "      we will instead use the Pytorch class nn.Linear for a linear layer, which does all that for us. Pytorch has many types of predefined layers that can greatly simplify our code, and often makes it faster too.\n",
        "'''\n",
        "\n",
        "###############################################################"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1. We continue to refactor our code. \\n      Instead of manually defining and initializing self.weights and self.bias, and calculating xb  @ self.weights + self.bias, \\n      we will instead use the Pytorch class nn.Linear for a linear layer, which does all that for us. Pytorch has many types of predefined layers that can greatly simplify our code, and often makes it faster too.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1tIwhaMdBRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(784,10)\n",
        "\n",
        "    def forward(self, xb): return self.lin(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLdZsQk0dgcp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "452970f0-0df7-49cd-dbe9-9e933999d2d2"
      },
      "source": [
        "model = Mnist_Logistic()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3312, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBZd3IxDdwBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk0M1oLjdzR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b357fd5f-436d-4bb1-fcbe-f0d042e32818"
      },
      "source": [
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0806, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlvLGlGGd0FQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "759d7fbd-3ca3-4db3-8b80-649814f40311"
      },
      "source": [
        "###########################################################\n",
        "# Refactor using optim\n",
        "'''\n",
        "\n",
        "Pytorch also has a package with various optimization algorithms, torch.optim. We can use the step method from our optimizer to take a forward step, instead of manually updating each parameter.\n",
        "\n",
        "This will let us replace our previous manually coded optimization step:\n",
        "\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "and instead use just:\n",
        "\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "(optim.zero_grad() resets the gradient to 0 and we need to call it before computing the gradient for the next minibatch.)\n",
        "\n",
        "'''\n",
        "###########################################################\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nPytorch also has a package with various optimization algorithms, torch.optim. We can use the step method from our optimizer to take a forward step, instead of manually updating each parameter.\\n\\nThis will let us replace our previous manually coded optimization step:\\n\\nwith torch.no_grad():\\n    for p in model.parameters(): p -= p.grad * lr\\n    model.zero_grad()\\nand instead use just:\\n\\nopt.step()\\nopt.zero_grad()\\n(optim.zero_grad() resets the gradient to 0 and we need to call it before computing the gradient for the next minibatch.)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ryfXbPGezci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "# We'll define a little function to create our model and optimizer so we can reuse it in the future.\n",
        "def get_model():\n",
        "    model = Mnist_Logistic()\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU_qnSRje-7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff32a9c5-2db1-4ece-9ed3-60f29e130e7a"
      },
      "source": [
        "model,opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3399, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S45GPFENfC6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DctyDF6AfPAR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8931d3bb-e9d7-4e51-dced-88a48facd352"
      },
      "source": [
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0810, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf-spD_nfbXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e58a4d9a-f3d2-4d64-d5be-20ba20c24ae8"
      },
      "source": [
        "###########################################################\n",
        "# Refactor using Dataset\n",
        "'''\n",
        "  PyTorch has an abstract Dataset class. \n",
        "  A Dataset can be anything that has a __len__ function (called by Python's standard len function) and a __getitem__ function as a way of indexing into it. \n",
        "  This tutorial walks through a nice example of creating a custom FacialLandmarkDataset class as a subclass of Dataset.\n",
        "\n",
        "  PyTorch's TensorDataset is a Dataset wrapping tensors. \n",
        "  By defining a length and way of indexing, this also gives us a way to iterate, index, and slice along the first dimension of a tensor. \n",
        "  This will make it easier to access both the independent and dependent variables in the same line as we train.\n",
        "\n",
        "'''\n",
        "###########################################################"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n  PyTorch has an abstract Dataset class. \\n  A Dataset can be anything that has a __len__ function (called by Python's standard len function) and a __getitem__ function as a way of indexing into it. \\n  This tutorial walks through a nice example of creating a custom FacialLandmarkDataset class as a subclass of Dataset.\\n\\n  PyTorch's TensorDataset is a Dataset wrapping tensors. \\n  By defining a length and way of indexing, this also gives us a way to iterate, index, and slice along the first dimension of a tensor. \\n  This will make it easier to access both the independent and dependent variables in the same line as we train.\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9lHIcdjhQmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c63d7bf-6db3-47e3-b0f2-59d34abe8a94"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "print(train_ds)\n",
        "\n",
        "model,opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataset.TensorDataset object at 0x7f38263b3e48>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wB2zAS2hZxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ace6d92-ed21-48cd-9a88-19f92a8221b8"
      },
      "source": [
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0807, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuoY82HghbHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}